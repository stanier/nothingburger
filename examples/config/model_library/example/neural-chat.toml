name = "NeuralChat"
author = "Intel"
license = "Apache 2.0"
website = "https://huggingface.co/Intel/neural-chat-7b-v3-3"

[service]
provider = "ollama"
base_url = "http://localhost:11434"
model_key = "neural-chat:7b-v3.3-q8_0"

[generation]
temperature = 0.0
top_k = -1
top_p = 1.0
max_tokens = 128
seed = -1
batch = 1
threads = 8
presence_penalty = 0.0
frequency_penalty = 1.07
stop = ["<stop>", "\n###"]

#[generation.rope]
#freq_base = 1.0
#freq_scale = 3.2

[generation.mirostat]
mode = 0
eta = 0.1
tau = 5.0